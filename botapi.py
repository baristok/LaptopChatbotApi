from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import Response
from pydantic import BaseModel
import subprocess
import os
import json
import requests
from bs4 import BeautifulSoup
from fastapi import Query
from nlp import WORD_GROUPS
import pandas as pd

def get_akakce_image(url):
    try:
        headers = {'User-Agent': 'Mozilla/5.0'}
        r = requests.get(url, headers=headers, timeout=10)
        soup = BeautifulSoup(r.text, 'html.parser')
        # Ana Ã¼rÃ¼n gÃ¶rseli <a class="img_w"> iÃ§inde href'te
        a_tag = soup.find('a', {'class': 'img_w'})
        if a_tag and a_tag.get('href'):
            img_url = a_tag['href']
            # EÄŸer link // ile baÅŸlÄ±yorsa baÅŸÄ±na https: ekle
            if img_url.startswith('//'):
                img_url = 'https:' + img_url
            return img_url
    except Exception as e:
        print(f"GÃ¶rsel Ã§ekme hatasÄ±: {e}")
    return None


app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

class PromptInput(BaseModel):
    prompt: str

@app.post("/get-suggestions/")
async def get_suggestions(data: PromptInput):
    try:
        command = f'python3 cli.py --prompt "{data.prompt}"'
        env = os.environ.copy()
        env["PYTHONIOENCODING"] = "utf-8"

        result = subprocess.run(
            command,
            shell=True,
            capture_output=True,
            encoding="utf-8",
            errors="replace",
            env=env
        )

        stdout = result.stdout.strip()
        stderr = result.stderr.strip()

        if result.returncode != 0:
            error_json = json.dumps({"hata": stderr or "Komut hatasÄ±"}, ensure_ascii=False)
            return Response(content=error_json, media_type="application/json")

        # Kelime gruplarÄ±ndan herhangi biri geÃ§iyor mu kontrol et
        should_ask_brand = False
        for words in WORD_GROUPS.values():
            if any(word in data.prompt.lower() for word in words):
                should_ask_brand = True
                break

        # ğŸ¯ TÃ¼rkÃ§e karakterleri kaÃ§Ä±rmadan encode et
        json_data = json.dumps({
            "cevap": stdout or "Bot bir yanÄ±t Ã¼retemedi.",
            "recommendations": [],
            "brand_warning": None,
            "ask_brand": should_ask_brand
        }, ensure_ascii=False)
        return Response(content=json_data, media_type="application/json")

    except Exception as e:
        error_json = json.dumps({"hata": str(e)}, ensure_ascii=False)
        return Response(content=error_json, media_type="application/json")

# CSV dosyalarÄ±nÄ± bir kere yÃ¼kle
laptop_df = pd.read_csv("latent_vektorlu_laptoplar.csv")
tam_veri_df = pd.read_csv("tamveriseti.csv")

def normalize_url(url):
    """URL'yi normalize eder, http:// veya https:// farkÄ±nÄ± giderir ve Ã¶nemli kÄ±smÄ± korur"""
    # URL'den http/https protokolÃ¼nÃ¼ Ã§Ä±kar
    if "://" in url:
        url = url.split("://")[1]
    elif "//" in url and not url.startswith("//"):
        url = url.split("//")[1]
    
    # ÃœrÃ¼n ID kÄ±smÄ±nÄ± al (genellikle son kÄ±sÄ±m)
    if "fiyati," in url:
        product_id = url.split("fiyati,")[-1].split(".html")[0]
        return product_id
    
    return url

@app.get("/get-image/")
async def get_image(url: str = Query(..., description="ÃœrÃ¼n sayfasÄ± URL'si")):
    try:
        # URL'yi normalize et
        normalized_url = normalize_url(url)
        image_url = None
        
        # Ä°lk olarak latent_vektorlu_laptoplar.csv'de ara
        found_in_latent = find_image_in_csv(laptop_df, url, normalized_url)
        if found_in_latent:
            print(f"GÃ¶rsel latent_vektorlu_laptoplar.csv'den bulundu: {url}")
            return {"image_url": found_in_latent, "source": "latent_csv"}
            
        # Bulunamazsa tamveriseti.csv'de ara
        found_in_tam = find_image_in_csv(tam_veri_df, url, normalized_url)
        if found_in_tam:
            print(f"GÃ¶rsel tamveriseti.csv'den bulundu: {url}")
            return {"image_url": found_in_tam, "source": "tam_csv"}
        
        # CSV'lerde bulunamazsa web'den al
        print(f"GÃ¶rsel CSV'lerde bulunamadÄ±, web'den alÄ±nÄ±yor: {url}")
        fallback_image_url = get_akakce_image(url)
        if fallback_image_url:
            print(f"GÃ¶rsel web'den alÄ±ndÄ±: {url}")
            return {"image_url": fallback_image_url, "source": "web"}
            
        print(f"GÃ¶rsel hiÃ§bir yerden bulunamadÄ±: {url}")
        return {"error": "GÃ¶rsel bulunamadÄ±", "source": "none"}
    except Exception as e:
        print(f"GÃ¶rsel Ã§ekme hatasÄ±: {e}")
        return {"error": f"GÃ¶rsel Ã§ekilirken hata oluÅŸtu: {str(e)}", "source": "error"}

def find_image_in_csv(df, original_url, normalized_url):
    """Verilen DataFrame'de gÃ¶rsel URL'sini bulmak iÃ§in kullanÄ±lÄ±r"""
    # Tam URL eÅŸleÅŸmesi dene
    laptop_row = df[df['Urun_URL'] == original_url]
    
    # EÄŸer bulunamazsa, normalize edilmiÅŸ URL'yi iÃ§eren satÄ±rlarÄ± ara
    if laptop_row.empty:
        # CSV'deki her URL'yi normalize et ve karÅŸÄ±laÅŸtÄ±r
        df['normalized_url'] = df['Urun_URL'].apply(normalize_url)
        laptop_row = df[df['normalized_url'] == normalized_url]
        # GeÃ§ici sÃ¼tunu temizle
        if 'normalized_url' in df.columns:
            df.drop('normalized_url', axis=1, inplace=True)
    
    if not laptop_row.empty and 'Gorsel_URL' in df.columns:
        image_url = laptop_row.iloc[0]['Gorsel_URL']
        if image_url and str(image_url) != 'nan':
            return image_url
    
    return None

@app.post("/ping")
async def keep_alive():
    # Basit bir yanÄ±t dÃ¶ner, bu endpoint API'nin boÅŸa dÃ¼ÅŸmemesi iÃ§in Ã§aÄŸrÄ±lÄ±r.
    return {"message": "API is alive"}
